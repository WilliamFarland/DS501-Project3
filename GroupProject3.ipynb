{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 3\n",
    "# DS 501 - Introduction to Data Science\n",
    "# Group 3&5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "# Problem 1 (20 points): Complete Exercise 2: Sentiment Analysis on Movie Reviews from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1; Problem 1: Downloading Data\n",
    "Modify the solution on Exercise 2 so that it can run in this iPython notebook\n",
    "* This will likely involved moving around data files and/or small modifications to the script."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download Data Script"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"Script to download the movie review dataset\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from hashlib import sha256\n",
    "import tarfile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "URL = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
    "\n",
    "ARCHIVE_SHA256 = \"fc0dccc2671af5db3c5d8f81f77a1ebfec953ecdd422334062df61ede36b2179\"\n",
    "ARCHIVE_NAME = Path(URL.rsplit(\"/\", 1)[1])\n",
    "DATA_FOLDER = Path(\"txt_sentoken\")\n",
    "\n",
    "\n",
    "if not DATA_FOLDER.exists():\n",
    "\n",
    "    if not ARCHIVE_NAME.exists():\n",
    "        print(\"Downloading dataset from %s (3 MB)\" % URL)\n",
    "        opener = urlopen(URL)\n",
    "        with open(ARCHIVE_NAME, \"wb\") as archive:\n",
    "            archive.write(opener.read())\n",
    "\n",
    "    try:\n",
    "        print(\"Checking the integrity of the archive\")\n",
    "        assert sha256(ARCHIVE_NAME.read_bytes()).hexdigest() == ARCHIVE_SHA256\n",
    "\n",
    "        print(\"Decompressing %s\" % ARCHIVE_NAME)\n",
    "        with tarfile.open(ARCHIVE_NAME, \"r:gz\") as archive:\n",
    "            archive.extractall(path=\".\")\n",
    "\n",
    "    finally:\n",
    "        ARCHIVE_NAME.unlink()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2; Problem 1: Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check number of samples and if prev script(s) ran properly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the training data folder must be passed as first argument\n",
    "movie_reviews_data_folder = DATA_FOLDER\n",
    "dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
    "print(\"n_samples: %d\" % len(dataset.data))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 params - {'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.00\n",
      "1 params - {'vect__ngram_range': (1, 2)}; mean - 0.85; std - 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.87      0.88       260\n",
      "         pos       0.86      0.88      0.87       240\n",
      "\n",
      "    accuracy                           0.87       500\n",
      "   macro avg       0.87      0.87      0.87       500\n",
      "weighted avg       0.87      0.87      0.87       500\n",
      "\n",
      "[[226  34]\n",
      " [ 30 210]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split the dataset in training and test set:\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    dataset.data, dataset.target, test_size=0.25, random_state=None)\n",
    "\n",
    "# TASK: Build a vectorizer / classifier pipeline that filters out tokens\n",
    "# that are too rare or too frequent\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=3, max_df=0.95)),\n",
    "    ('clf', LinearSVC(C=5000)),\n",
    "])\n",
    "\n",
    "# TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "# more useful.\n",
    "# Fit the pipeline on the training set using grid search for the parameters\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "grid_search.fit(docs_train, y_train)\n",
    "\n",
    "# TASK: print the mean and std for each candidate along with the parameter\n",
    "# settings for all the candidates explored by grid search.\n",
    "n_candidates = len(grid_search.cv_results_['params'])\n",
    "for i in range(n_candidates):\n",
    "    print(i, 'params - %s; mean - %0.2f; std - %0.2f'\n",
    "          % (grid_search.cv_results_['params'][i],\n",
    "             grid_search.cv_results_['mean_test_score'][i],\n",
    "             grid_search.cv_results_['std_test_score'][i]))\n",
    "\n",
    "# TASK: Predict the outcome on the testing set and store it in a variable\n",
    "# named y_predicted\n",
    "y_predicted = grid_search.predict(docs_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))\n",
    "\n",
    "# Print and plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.matshow(cm)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Problem 2 (20 points): Explore the Scikit-learn TfidfVectorizer Class\n",
    "\n",
    "**Read the documentation for the TfidfVectorizer class at https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1; Problem 2:\n",
    " Define the term frequencyâ€“inverse document frequency (TF-IDF) statistic (https://en.wikipedia.org/wiki/Tf%E2%80%93idf) will likely help."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of TF-IDF\n",
    "\n",
    "TF-IDF stands for \"Term Frequency-Inverse Document Frequency.\" It is a way of figuring out how important a word is in a document or a piece of writing.\n",
    "\n",
    "Let's say you have a book about cats. In this book, the word \"cat\" is used a lot because it's the main topic of the book. But the word \"dog\" is only used a few times because it's not really related to the subject of the book.\n",
    "\n",
    "TF-IDF takes into account both the number of times a word appears in a document (the \"Term Frequency\") and how rare that word is in all the other documents (the \"Inverse Document Frequency\").\n",
    "\n",
    "So, in the example of the book about cats, the word \"cat\" would have a high TF-IDF score because it appears frequently in the book and is relevant to the topic. The word \"dog\" would have a low TF-IDF score because it appears infrequently and is not as relevant to the topic.\n",
    "\n",
    "Basically, TF-IDF helps us understand which words are most important in a document and which ones are less important."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2; Problem 2:\n",
    " Run the TfidfVectorizer class on the training data above (docs_train).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: (1500, 252)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      about    acting    action     actor    actors  actually     after  \\\n0  0.106897  0.020711  0.000000  0.022802  0.042791  0.000000  0.000000   \n1  0.000000  0.000000  0.069684  0.000000  0.073734  0.000000  0.050012   \n2  0.000000  0.000000  0.175705  0.000000  0.000000  0.000000  0.063051   \n3  0.050233  0.087594  0.000000  0.000000  0.000000  0.000000  0.000000   \n4  0.043636  0.076091  0.074286  0.000000  0.000000  0.074134  0.000000   \n\n      again       all    almost  ...  without     work     world     would  \\\n0  0.021185  0.077459  0.020409  ...      0.0  0.00000  0.181235  0.056831   \n1  0.000000  0.076270  0.000000  ...      0.0  0.00000  0.000000  0.146893   \n2  0.092043  0.096155  0.000000  ...      0.0  0.00000  0.000000  0.000000   \n3  0.000000  0.093599  0.000000  ...      0.0  0.00000  0.000000  0.000000   \n4  0.000000  0.162614  0.000000  ...      0.0  0.13433  0.073982  0.000000   \n\n       year     years       yet       you     young     your  \n0  0.000000  0.019754  0.000000  0.175588  0.000000  0.02022  \n1  0.000000  0.000000  0.000000  0.201709  0.073410  0.00000  \n2  0.085657  0.000000  0.000000  0.101720  0.092549  0.00000  \n3  0.000000  0.000000  0.000000  0.049507  0.000000  0.00000  \n4  0.000000  0.000000  0.080483  0.043006  0.000000  0.00000  \n\n[5 rows x 252 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>about</th>\n      <th>acting</th>\n      <th>action</th>\n      <th>actor</th>\n      <th>actors</th>\n      <th>actually</th>\n      <th>after</th>\n      <th>again</th>\n      <th>all</th>\n      <th>almost</th>\n      <th>...</th>\n      <th>without</th>\n      <th>work</th>\n      <th>world</th>\n      <th>would</th>\n      <th>year</th>\n      <th>years</th>\n      <th>yet</th>\n      <th>you</th>\n      <th>young</th>\n      <th>your</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.106897</td>\n      <td>0.020711</td>\n      <td>0.000000</td>\n      <td>0.022802</td>\n      <td>0.042791</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.021185</td>\n      <td>0.077459</td>\n      <td>0.020409</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.181235</td>\n      <td>0.056831</td>\n      <td>0.000000</td>\n      <td>0.019754</td>\n      <td>0.000000</td>\n      <td>0.175588</td>\n      <td>0.000000</td>\n      <td>0.02022</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.069684</td>\n      <td>0.000000</td>\n      <td>0.073734</td>\n      <td>0.000000</td>\n      <td>0.050012</td>\n      <td>0.000000</td>\n      <td>0.076270</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.146893</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.201709</td>\n      <td>0.073410</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.175705</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.063051</td>\n      <td>0.092043</td>\n      <td>0.096155</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.085657</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.101720</td>\n      <td>0.092549</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.050233</td>\n      <td>0.087594</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.093599</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.049507</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.043636</td>\n      <td>0.076091</td>\n      <td>0.074286</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.074134</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.162614</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.13433</td>\n      <td>0.073982</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.080483</td>\n      <td>0.043006</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 252 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def run_vectorizer(min, max):\n",
    "    vectorizer = TfidfVectorizer(min_df=min, max_df=max)\n",
    "\n",
    "\n",
    "    vectors = vectorizer.fit_transform(docs_train)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "    print(f\"Output Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "df = run_vectorizer(0.2, 0.95)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 3; Problem 2:\n",
    "- Explore the min_df and max_df parameters of TfidfVectorizer.\n",
    "- What do they mean? How do they change the features you get?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Book Definition\n",
    "\n",
    "**min_df definition: min_dffloat or int, default=1**\n",
    "    - When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "**max_df definition: max_dffloat or int, default=1.0**\n",
    "    - When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "Explanation:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Min DF =0, Max DF=0.95"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: (1500, 35341)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    00  000  0009f  007  00s   03   04   05  05425   10  ...  zuko  zukovsky  \\\n0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n1  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n2  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n3  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n4  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n\n   zulu  zundel  zurg  zweibel  zwick  zwigoff  zycie  zzzzzzz  \n0   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n1   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n2   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n3   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n4   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n\n[5 rows x 35341 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>0009f</th>\n      <th>007</th>\n      <th>00s</th>\n      <th>03</th>\n      <th>04</th>\n      <th>05</th>\n      <th>05425</th>\n      <th>10</th>\n      <th>...</th>\n      <th>zuko</th>\n      <th>zukovsky</th>\n      <th>zulu</th>\n      <th>zundel</th>\n      <th>zurg</th>\n      <th>zweibel</th>\n      <th>zwick</th>\n      <th>zwigoff</th>\n      <th>zycie</th>\n      <th>zzzzzzz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 35341 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_vectorizer(0, 0.95)\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Min DF =0.5, Max DF=0.95"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: (1500, 66)\n"
     ]
    },
    {
     "data": {
      "text/plain": "      about     after       all      also        an       are        at  \\\n0  0.149481  0.000000  0.108316  0.061769  0.056161  0.156214  0.043913   \n1  0.000000  0.068128  0.103896  0.069124  0.047136  0.238383  0.049141   \n2  0.000000  0.102781  0.156744  0.000000  0.000000  0.000000  0.000000   \n3  0.077186  0.000000  0.143820  0.000000  0.130498  0.131994  0.068025   \n4  0.060163  0.000000  0.224202  0.000000  0.254292  0.051441  0.000000   \n\n         be      been       but  ...       way        we      well      what  \\\n0  0.127383  0.000000  0.172443  ...  0.042212  0.059963  0.020433  0.170431   \n1  0.285101  0.136879  0.267196  ...  0.070858  0.000000  0.068597  0.057217   \n2  0.071687  0.103252  0.134369  ...  0.106900  0.000000  0.310466  0.086321   \n3  0.263104  0.094739  0.246580  ...  0.000000  0.000000  0.000000  0.079204   \n4  0.102538  0.073844  0.192197  ...  0.000000  0.144804  0.074014  0.185207   \n\n       when     which       who      will     would       you  \n0  0.066714  0.071223  0.171103  0.000000  0.079471  0.245536  \n1  0.055993  0.000000  0.047869  0.000000  0.200100  0.274772  \n2  0.084474  0.000000  0.144435  0.000000  0.000000  0.165814  \n3  0.000000  0.082748  0.132527  0.094811  0.000000  0.076071  \n4  0.120829  0.000000  0.103298  0.000000  0.000000  0.059294  \n\n[5 rows x 66 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>about</th>\n      <th>after</th>\n      <th>all</th>\n      <th>also</th>\n      <th>an</th>\n      <th>are</th>\n      <th>at</th>\n      <th>be</th>\n      <th>been</th>\n      <th>but</th>\n      <th>...</th>\n      <th>way</th>\n      <th>we</th>\n      <th>well</th>\n      <th>what</th>\n      <th>when</th>\n      <th>which</th>\n      <th>who</th>\n      <th>will</th>\n      <th>would</th>\n      <th>you</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.149481</td>\n      <td>0.000000</td>\n      <td>0.108316</td>\n      <td>0.061769</td>\n      <td>0.056161</td>\n      <td>0.156214</td>\n      <td>0.043913</td>\n      <td>0.127383</td>\n      <td>0.000000</td>\n      <td>0.172443</td>\n      <td>...</td>\n      <td>0.042212</td>\n      <td>0.059963</td>\n      <td>0.020433</td>\n      <td>0.170431</td>\n      <td>0.066714</td>\n      <td>0.071223</td>\n      <td>0.171103</td>\n      <td>0.000000</td>\n      <td>0.079471</td>\n      <td>0.245536</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.068128</td>\n      <td>0.103896</td>\n      <td>0.069124</td>\n      <td>0.047136</td>\n      <td>0.238383</td>\n      <td>0.049141</td>\n      <td>0.285101</td>\n      <td>0.136879</td>\n      <td>0.267196</td>\n      <td>...</td>\n      <td>0.070858</td>\n      <td>0.000000</td>\n      <td>0.068597</td>\n      <td>0.057217</td>\n      <td>0.055993</td>\n      <td>0.000000</td>\n      <td>0.047869</td>\n      <td>0.000000</td>\n      <td>0.200100</td>\n      <td>0.274772</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.102781</td>\n      <td>0.156744</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.071687</td>\n      <td>0.103252</td>\n      <td>0.134369</td>\n      <td>...</td>\n      <td>0.106900</td>\n      <td>0.000000</td>\n      <td>0.310466</td>\n      <td>0.086321</td>\n      <td>0.084474</td>\n      <td>0.000000</td>\n      <td>0.144435</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.165814</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.077186</td>\n      <td>0.000000</td>\n      <td>0.143820</td>\n      <td>0.000000</td>\n      <td>0.130498</td>\n      <td>0.131994</td>\n      <td>0.068025</td>\n      <td>0.263104</td>\n      <td>0.094739</td>\n      <td>0.246580</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.079204</td>\n      <td>0.000000</td>\n      <td>0.082748</td>\n      <td>0.132527</td>\n      <td>0.094811</td>\n      <td>0.000000</td>\n      <td>0.076071</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.060163</td>\n      <td>0.000000</td>\n      <td>0.224202</td>\n      <td>0.000000</td>\n      <td>0.254292</td>\n      <td>0.051441</td>\n      <td>0.000000</td>\n      <td>0.102538</td>\n      <td>0.073844</td>\n      <td>0.192197</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.144804</td>\n      <td>0.074014</td>\n      <td>0.185207</td>\n      <td>0.120829</td>\n      <td>0.000000</td>\n      <td>0.103298</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.059294</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 66 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_vectorizer(0.5, 0.95)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Answer:\n",
    "\n",
    "As we can see from the above examples changes the min df and max df changes the result words.\n",
    "\n",
    "If we increase the maximum this selects words that are more common throughout the document(s) such as: by, for it, on\n",
    "These very high frequency words might not be that interesting to the topic of the document or sentiment.\n",
    "\n",
    "If we decrease the minimum to 0 we see words such as yau, yatf, yearbook, zukovsky. These are very infrequent words that also might not be that interesting to the general sentiment of the document.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part 4; Problem 2\n",
    "Explore the ngram_range parameter of TfidfVectorizer. What does it mean? How does it change the features you get? (Note, large values  of ngram_range may take a long time to run!)\n",
    "\n",
    "**ngram_rangetuple (min_n, max_n), default=(1, 1)**\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used. For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Min DF=0.9, Max DF=.99"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: (1500, 34810)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    00  000  0009f  007  00s   03   04   05  05425   10  ...  zuko  zukovsky  \\\n0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n1  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n2  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n3  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n4  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  ...   0.0       0.0   \n\n   zulu  zundel  zurg  zweibel  zwick  zwigoff  zycie  zzzzzzz  \n0   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n1   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n2   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n3   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n4   0.0     0.0   0.0      0.0    0.0      0.0    0.0      0.0  \n\n[5 rows x 34810 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>0009f</th>\n      <th>007</th>\n      <th>00s</th>\n      <th>03</th>\n      <th>04</th>\n      <th>05</th>\n      <th>05425</th>\n      <th>10</th>\n      <th>...</th>\n      <th>zuko</th>\n      <th>zukovsky</th>\n      <th>zulu</th>\n      <th>zundel</th>\n      <th>zurg</th>\n      <th>zweibel</th>\n      <th>zwick</th>\n      <th>zwigoff</th>\n      <th>zycie</th>\n      <th>zzzzzzz</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 34810 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_vectorizer(0, 0.1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Definition** ngram_rangetuple (min_n, max_n), default=(1, 1)\n",
    "The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used. For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Code Example\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Problem 3 (20 points): Machine Learning Algorithms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based upon Problem 2, pick some parameters for TfidfVectorizer\n",
    "    * \"fit\" your TfidfVectorizer using docs_train\n",
    "    * Compute \"Xtrain\", a Tf-idf-weighted document-term matrix using the transform function on docs_train\n",
    "    * Compute \"Xtest\", a Tf-idf-weighted document-term matrix using the transform function on docs_test\n",
    "    * Note, be sure to use the same Tf-idf-weighted class (**\"fit\" using docs_train**) to transform **both** docs_test and docs_train\n",
    "* Examine two classifiers provided by scikit-learn \n",
    "    * LinearSVC\n",
    "    * KNeighborsClassifier\n",
    "    * Try a number of different parameter settings for each and judge your performance using a confusion matrix (see Problem 1 for an example).\n",
    "* Does one classifier, or one set of parameters work better?\n",
    "    * Why do you think it might be working better?\n",
    "* For a particular choice of parameters and classifier, look at 2 examples where the prediction was incorrect.\n",
    "    * Can you conjecture on why the classifier made a mistake for this prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=Pipeline(steps=[('vect',\n                                        TfidfVectorizer(max_df=0.9, min_df=3)),\n                                       ('clf',\n                                        KNeighborsClassifier(n_neighbors=3))]),\n             n_jobs=-1,\n             param_grid={'clf__n_neighbors': [3, 12, 15, 20],\n                         'vect__max_df': [0.7, 0.8, 0.9, 0.95],\n                         'vect__min_df': [3, 4, 5, 6],\n                         'vect__ngram_range': [(1, 1), (1, 3)]})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=3, max_df=0.90)\n",
    "\n",
    "pipeline1 = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', LinearSVC(C=15000)),\n",
    "])\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=3)),\n",
    "])\n",
    "\n",
    "\n",
    "parameters1 = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 3)],\n",
    "    'vect__min_df': [3, 4, 5, 6],\n",
    "    'vect__max_df': [0.7, 0.8, 0.9, 0.95]\n",
    "}\n",
    "\n",
    "parameters2 = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 3)],\n",
    "    'clf__n_neighbors': [3, 12, 15, 20],\n",
    "    'vect__min_df': [3, 4, 5, 6],\n",
    "    'vect__max_df': [0.7, 0.8, 0.9, 0.95]\n",
    "}\n",
    "\n",
    "grid_search_linear = GridSearchCV(pipeline1, parameters1, n_jobs=-1)\n",
    "grid_search_linear.fit(docs_train, y_train)\n",
    "\n",
    "grid_search_knn = GridSearchCV(pipeline2,parameters2, n_jobs=-1)\n",
    "grid_search_knn.fit(docs_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Linear: \n",
      "\n",
      "0 params - {'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.84; std - 0.00\n",
      "1 params - {'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "2 params - {'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.84; std - 0.00\n",
      "3 params - {'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "4 params - {'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.84; std - 0.00\n",
      "5 params - {'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "6 params - {'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.84; std - 0.01\n",
      "7 params - {'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.86; std - 0.02\n",
      "8 params - {'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.84; std - 0.00\n",
      "9 params - {'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "10 params - {'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.84; std - 0.01\n",
      "11 params - {'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "12 params - {'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.01\n",
      "13 params - {'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "14 params - {'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.00\n",
      "15 params - {'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.86; std - 0.02\n",
      "16 params - {'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.00\n",
      "17 params - {'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "18 params - {'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.01\n",
      "19 params - {'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "20 params - {'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.01\n",
      "21 params - {'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "22 params - {'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.01\n",
      "23 params - {'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.86; std - 0.02\n",
      "24 params - {'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.00\n",
      "25 params - {'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "26 params - {'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.00\n",
      "27 params - {'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "28 params - {'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.01\n",
      "29 params - {'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.85; std - 0.02\n",
      "30 params - {'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.83; std - 0.01\n",
      "31 params - {'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.86; std - 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.87      0.88       260\n",
      "         pos       0.86      0.87      0.87       240\n",
      "\n",
      "    accuracy                           0.87       500\n",
      "   macro avg       0.87      0.87      0.87       500\n",
      "weighted avg       0.87      0.87      0.87       500\n",
      "\n",
      "[[227  33]\n",
      " [ 31 209]]\n",
      "Performance of KNN: \n",
      "\n",
      "0 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "1 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.66; std - 0.04\n",
      "2 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "3 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.67; std - 0.03\n",
      "4 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.04\n",
      "5 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.03\n",
      "6 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.04\n",
      "7 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.67; std - 0.04\n",
      "8 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "9 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.02\n",
      "10 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "11 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.67; std - 0.03\n",
      "12 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "13 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.04\n",
      "14 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "15 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.04\n",
      "16 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.02\n",
      "17 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.69; std - 0.04\n",
      "18 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.67; std - 0.03\n",
      "19 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.04\n",
      "20 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "21 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.69; std - 0.04\n",
      "22 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.67; std - 0.03\n",
      "23 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.04\n",
      "24 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.02\n",
      "25 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.04\n",
      "26 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.67; std - 0.02\n",
      "27 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.04\n",
      "28 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.67; std - 0.03\n",
      "29 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.69; std - 0.04\n",
      "30 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.66; std - 0.03\n",
      "31 params - {'clf__n_neighbors': 3, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.69; std - 0.04\n",
      "32 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.69; std - 0.02\n",
      "33 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "34 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "35 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.03\n",
      "36 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "37 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "38 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "39 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.69; std - 0.02\n",
      "40 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.69; std - 0.01\n",
      "41 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.01\n",
      "42 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "43 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "44 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.69; std - 0.02\n",
      "45 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.01\n",
      "46 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.01\n",
      "47 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "48 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "49 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.03\n",
      "50 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "51 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "52 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "53 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "54 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "55 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "56 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "57 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.03\n",
      "58 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.03\n",
      "59 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "60 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "61 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.01\n",
      "62 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "63 params - {'clf__n_neighbors': 12, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "64 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "65 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "66 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "67 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "68 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "69 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.01\n",
      "70 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "71 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.01\n",
      "72 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "73 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.71; std - 0.02\n",
      "74 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.01\n",
      "75 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.71; std - 0.02\n",
      "76 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.01\n",
      "77 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.71; std - 0.01\n",
      "78 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "79 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.72; std - 0.01\n",
      "80 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "81 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.03\n",
      "82 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.02\n",
      "83 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.01\n",
      "84 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "85 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.68; std - 0.02\n",
      "86 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "87 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "88 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "89 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.69; std - 0.02\n",
      "90 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.03\n",
      "91 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.69; std - 0.02\n",
      "92 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.03\n",
      "93 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "94 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "95 params - {'clf__n_neighbors': 15, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "96 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.03\n",
      "97 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.71; std - 0.03\n",
      "98 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "99 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.72; std - 0.02\n",
      "100 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.03\n",
      "101 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.72; std - 0.02\n",
      "102 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.03\n",
      "103 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.7, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.73; std - 0.02\n",
      "104 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.01\n",
      "105 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.73; std - 0.02\n",
      "106 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.02\n",
      "107 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.73; std - 0.03\n",
      "108 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.02\n",
      "109 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.73; std - 0.02\n",
      "110 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.70; std - 0.03\n",
      "111 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.8, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.73; std - 0.01\n",
      "112 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.01\n",
      "113 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "114 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.02\n",
      "115 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.72; std - 0.02\n",
      "116 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.03\n",
      "117 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.71; std - 0.03\n",
      "118 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "119 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.9, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.72; std - 0.02\n",
      "120 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 1)}; mean - 0.73; std - 0.01\n",
      "121 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 3, 'vect__ngram_range': (1, 3)}; mean - 0.70; std - 0.02\n",
      "122 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.02\n",
      "123 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 4, 'vect__ngram_range': (1, 3)}; mean - 0.71; std - 0.03\n",
      "124 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 1)}; mean - 0.72; std - 0.02\n",
      "125 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 5, 'vect__ngram_range': (1, 3)}; mean - 0.71; std - 0.02\n",
      "126 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 1)}; mean - 0.71; std - 0.02\n",
      "127 params - {'clf__n_neighbors': 20, 'vect__max_df': 0.95, 'vect__min_df': 6, 'vect__ngram_range': (1, 3)}; mean - 0.72; std - 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.75      0.74      0.74       260\n",
      "         pos       0.72      0.73      0.73       240\n",
      "\n",
      "    accuracy                           0.74       500\n",
      "   macro avg       0.74      0.74      0.74       500\n",
      "weighted avg       0.74      0.74      0.74       500\n",
      "\n",
      "[[192  68]\n",
      " [ 64 176]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Performance\n",
    "\n",
    "def calculate_performance_stats(grid_search):\n",
    "    # TASK: print the mean and std for each candidate along with the parameter\n",
    "    # settings for all the candidates explored by grid search.\n",
    "    n_candidates = len(grid_search.cv_results_['params'])\n",
    "    for i in range(n_candidates):\n",
    "        print(i, 'params - %s; mean - %0.2f; std - %0.2f'\n",
    "              % (grid_search.cv_results_['params'][i],\n",
    "                 grid_search.cv_results_['mean_test_score'][i],\n",
    "                 grid_search.cv_results_['std_test_score'][i]))\n",
    "\n",
    "    # TASK: Predict the outcome on the testing set and store it in a variable\n",
    "    # named y_predicted\n",
    "    y_predicted = grid_search.predict(docs_test)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(metrics.classification_report(y_test, y_predicted,\n",
    "                                        target_names=dataset.target_names))\n",
    "\n",
    "    # Print and plot the confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "    print(cm)\n",
    "\n",
    "print(\"Performance of Linear: \\n\")\n",
    "calculate_performance_stats(grid_search_linear)\n",
    "\n",
    "print(\"Performance of KNN: \\n\")\n",
    "calculate_performance_stats(grid_search_knn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 4 (20 points): Open Ended Question:  Finding the Right Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you find a two-dimensional plot in which the positive and negative reviews are separated?\n",
    "    * This problem is hard since you will likely have thousands of features for review, and you will need to transform these thousands of features into just two numbers (so that you can make a 2D plot).\n",
    "* Note, I was not able to find such a plot myself!\n",
    "    * So, this problem is about **trying** but perhaps **not necessarily succeeding**!\n",
    "* I tried two things, neither of which worked very well.\n",
    "    * I first plotted the length of the review versus the number of features we compute that are in that review\n",
    "    * Second I used Principle Component Analysis on a subset of the features.\n",
    "* Can you do better than I did!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "train_vectors = vectorizer.fit_transform(docs_train)\n",
    "test_vectors = vectorizer.transform(docs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 4.881511s; Prediction time: 1.421338s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(y_test, prediction_linear, output_dict=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 21)\t0.04584665190953572\n",
      "  (0, 88)\t0.0354817542613837\n",
      "  (0, 133)\t0.024123623493751245\n",
      "  (0, 138)\t0.03481938654311024\n",
      "  (0, 139)\t0.029385559421139386\n",
      "  (0, 218)\t0.025867513603235567\n",
      "  (0, 220)\t0.018990410805850663\n",
      "  (0, 228)\t0.020907376469974006\n",
      "  (0, 229)\t0.0332153165270937\n",
      "  (0, 231)\t0.04011180839780755\n",
      "  (0, 298)\t0.047564583248325736\n",
      "  (0, 332)\t0.019424333553340254\n",
      "  (0, 367)\t0.031108932148020733\n",
      "  (0, 402)\t0.03232646009228996\n",
      "  (0, 403)\t0.029889385341397224\n",
      "  (0, 418)\t0.018713277662545623\n",
      "  (0, 420)\t0.020831586960207083\n",
      "  (0, 426)\t0.02833279753243769\n",
      "  (0, 434)\t0.04695144128484003\n",
      "  (0, 442)\t0.04487215861753387\n",
      "  (0, 475)\t0.1181657834560634\n",
      "  (0, 500)\t0.13463770100223024\n",
      "  (0, 503)\t0.037109262511126284\n",
      "  (0, 522)\t0.049283159671242284\n",
      "  (0, 523)\t0.05158149542126388\n",
      "  :\t:\n",
      "  (1499, 10174)\t0.07689981779560152\n",
      "  (1499, 10197)\t0.030734657242124836\n",
      "  (1499, 10328)\t0.10659486184143849\n",
      "  (1499, 10331)\t0.11055173458836035\n",
      "  (1499, 10343)\t0.0706309073414588\n",
      "  (1499, 10358)\t0.06456473007675248\n",
      "  (1499, 10396)\t0.05244006340035493\n",
      "  (1499, 10397)\t0.11055173458836035\n",
      "  (1499, 10402)\t0.07086577712122742\n",
      "  (1499, 10411)\t0.029024467031232664\n",
      "  (1499, 10418)\t0.06667403459453697\n",
      "  (1499, 10802)\t0.06630459604169806\n",
      "  (1499, 10887)\t0.029661083420569907\n",
      "  (1499, 10891)\t0.028089248970311818\n",
      "  (1499, 10931)\t0.028714529393329035\n",
      "  (1499, 10937)\t0.036091932136975036\n",
      "  (1499, 10947)\t0.040552752812578786\n",
      "  (1499, 10952)\t0.023438528233454065\n",
      "  (1499, 11004)\t0.07481438943830587\n",
      "  (1499, 11015)\t0.06950107245262836\n",
      "  (1499, 11087)\t0.05929848003569971\n",
      "  (1499, 11094)\t0.09978198949546915\n",
      "  (1499, 11113)\t0.027920568420048728\n",
      "  (1499, 11169)\t0.054893955487882305\n",
      "  (1499, 11183)\t0.10846315761137114\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Bad Vs Good Words')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "negative_words = ['bad', 'terrible', 'overdoes', 'confusing', 'failure', 'fail', 'lack', 'mundane', 'painfully', 'painful']\n",
    "positive_words = ['good', 'great', 'worth', 'recommend', 'excellent', 'adequate', 'nice', 'positive', 'awesome']\n",
    "\n",
    "count_negative = []\n",
    "count_positive = []\n",
    "\n",
    "for count, docs in enumerate(docs_test):\n",
    "\n",
    "    number_of_negative = 0\n",
    "    number_of_positive = 0\n",
    "\n",
    "    for words in str(docs).split(' '):\n",
    "        if words in positive_words:\n",
    "            number_of_positive += 1\n",
    "        if words in negative_words:\n",
    "            number_of_negative += 1\n",
    "\n",
    "\n",
    "    count_negative.append(number_of_negative)\n",
    "    count_positive.append(number_of_positive)\n",
    "\n",
    "x_test = np.column_stack((count_positive, count_negative))\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(x_test, y_test)\n",
    "\n",
    "plt.scatter(count_negative, count_positive, c=y_test)\n",
    "plt.xlabel('# Of \"Negative Words\" in Doc')\n",
    "plt.ylabel('# Of \"Positive Words\" in Doc')\n",
    "plt.title('Bad Vs Good Words')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
